{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "IbNLDAeEaKHL",
    "outputId": "92c051e4-f75d-4eb6-833a-fe4fac250129"
   },
   "outputs": [],
   "source": [
    "# from https://medium.com/@aybukeyalcinerr/bag-of-visual-words-bovw-db9500331b2f\n",
    "# dataset https://www.kaggle.com/c/dogs-vs-cats/data?select=train.zip\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from scipy import ndimage\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# takes all images and convert them to grayscale. \n",
    "# return a dictionary that holds all images category by category. \n",
    "def load_images_from_folder(folder):\n",
    "    images = {}\n",
    "    for filename in os.listdir(folder):\n",
    "        category = []\n",
    "        path = folder + \"/\" + filename\n",
    "        for cat in os.listdir(path):\n",
    "            img = cv2.imread(path + \"/\" + cat,0)\n",
    "            if img is not None:\n",
    "                category.append(img)\n",
    "        images[filename] = category\n",
    "    return images\n",
    "\n",
    "images = load_images_from_folder(\"data/training_set\")  # take all images category by category \n",
    "test = load_images_from_folder(\"data/test_set\") # take test images \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JT5fS5qUeXuC"
   },
   "outputs": [],
   "source": [
    "# Creates descriptolsrs using sift \n",
    "# Takes one parameter that is images dictionary\n",
    "# Return an array whose first index holds the decriptor_list without an order\n",
    "# And the second index holds the sift_vectors dictionary which holds the descriptors but this is seperated class by class\n",
    "def sift_features(images):\n",
    "    sift_vectors = {}\n",
    "    descriptor_list = []\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    for key,value in images.items():\n",
    "        features = []\n",
    "        for img in value:\n",
    "            kp, des = sift.detectAndCompute(img,None)           \n",
    "            descriptor_list.extend(des)\n",
    "            features.append(des)\n",
    "        sift_vectors[key] = features\n",
    "    return [descriptor_list, sift_vectors]\n",
    "\n",
    "sifts = sift_features(images) \n",
    "# Takes the descriptor list which is unordered one\n",
    "descriptor_list = sifts[0] \n",
    "# Takes the sift features that is seperated class by class for train data\n",
    "all_bovw_feature = sifts[1] \n",
    "# Takes the sift features that is seperated class by class for test data\n",
    "test_bovw_feature = sift_features(test)[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsJcpBu2edcs"
   },
   "outputs": [],
   "source": [
    "# A k-means clustering algorithm who takes 2 parameter which is number \n",
    "# of cluster(k) and the other is descriptors list(unordered 1d array)\n",
    "# Returns an array that holds central points.\n",
    "def kmeans(k, descriptor_list):\n",
    "    kmeans = KMeans(n_clusters = k, n_init=10)\n",
    "    kmeans.fit(descriptor_list)\n",
    "    visual_words = kmeans.cluster_centers_ \n",
    "    return visual_words\n",
    "    \n",
    "# Takes the central points which is visual words    \n",
    "visual_words = kmeans(150, descriptor_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ovr6NtKmehMr"
   },
   "outputs": [],
   "source": [
    "# Takes 2 parameters. The first one is a dictionary that holds the descriptors that are separated class by class \n",
    "# And the second parameter is an array that holds the central points (visual words) of the k means clustering\n",
    "# Returns a dictionary that holds the histograms for each images that are separated class by class. \n",
    "def image_class(all_bovw, centers):\n",
    "    dict_feature = {}\n",
    "    for key,value in all_bovw.items():\n",
    "        category = []\n",
    "        for img in value:\n",
    "            histogram = np.zeros(len(centers))\n",
    "            for each_feature in img:\n",
    "                ind = find_index(each_feature, centers)\n",
    "                histogram[ind] += 1\n",
    "            category.append(histogram)\n",
    "        dict_feature[key] = category\n",
    "    return dict_feature\n",
    "    \n",
    "# Creates histograms for train data    \n",
    "bovw_train = image_class(all_bovw_feature, visual_words) \n",
    "# Creates histograms for test data\n",
    "bovw_test = image_class(test_bovw_feature, visual_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EbLax1hBekjb"
   },
   "outputs": [],
   "source": [
    "# 1-NN algorithm. We use this for predict the class of test images.\n",
    "# Takes 2 parameters. images is the feature vectors of train images and tests is the feature vectors of test images\n",
    "# Returns an array that holds number of test images, number of correctly predicted images and records of class based images respectively\n",
    "def knn(images, tests):\n",
    "    num_test = 0\n",
    "    correct_predict = 0\n",
    "    class_based = {}\n",
    "    \n",
    "    for test_key, test_val in tests.items():\n",
    "        class_based[test_key] = [0, 0] # [correct, all]\n",
    "        for tst in test_val:\n",
    "            predict_start = 0\n",
    "            #print(test_key)\n",
    "            minimum = 0\n",
    "            key = \"a\" #predicted\n",
    "            for train_key, train_val in images.items():\n",
    "                for train in train_val:\n",
    "                    if(predict_start == 0):\n",
    "                        minimum = distance.euclidean(tst, train)\n",
    "                        #minimum = L1_dist(tst,train)\n",
    "                        key = train_key\n",
    "                        predict_start += 1\n",
    "                    else:\n",
    "                        dist = distance.euclidean(tst, train)\n",
    "                        #dist = L1_dist(tst,train)\n",
    "                        if(dist < minimum):\n",
    "                            minimum = dist\n",
    "                            key = train_key\n",
    "            \n",
    "            if(test_key == key):\n",
    "                correct_predict += 1\n",
    "                class_based[test_key][0] += 1\n",
    "            num_test += 1\n",
    "            class_based[test_key][1] += 1\n",
    "            #print(minimum)\n",
    "    return [num_test, correct_predict, class_based]\n",
    "    \n",
    "# Call the knn function    \n",
    "results_bowl = knn(bovw_train, bovw_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "amdS2Vinemyl"
   },
   "outputs": [],
   "source": [
    "# Calculates the average accuracy and class based accuracies.  \n",
    "def accuracy(results):\n",
    "    avg_accuracy = (results[1] / results[0]) * 100\n",
    "    print(\"Average accuracy: %\" + str(avg_accuracy))\n",
    "    print(\"\\nClass based accuracies: \\n\")\n",
    "    for key,value in results[2].items():\n",
    "        acc = (value[0] / value[1]) * 100\n",
    "        print(key + \" : %\" + str(acc))\n",
    "        \n",
    "# Calculates the accuracies and write the results to the console.       \n",
    "accuracy(results_bowl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "data = cv2.imread(image_path)\n",
    "data = gray(data)\n",
    "keypoint, descriptor = features(data, extractor)\n",
    "histogram = build_histogram(descriptor, kmeans)\n",
    "neighbor = NearestNeighbors(n_neighbors = 1)\n",
    "neighbor.fit(preprocess_image)\n",
    "dist, result = neighbor.kneighbors([histogram])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BoVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
